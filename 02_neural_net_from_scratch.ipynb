{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Building a Neural Network from scratch\n",
    "======================================\n",
    "\n",
    "In this example we will build a simple neural network using JAX to predict the atomization energies of small molecules from the QM7 dataset.\n",
    "The key steps will be:\n",
    "- Define a model (which in this case takes as input a geometry and returns a predicted energy)\n",
    "- Define a loss\n",
    "- Define and run an optimizer that minimizes this loss\n",
    "\n",
    "We will see, that even when writing it from scratch, it's no more than a few lines of code.\n",
    "We first import some basic libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "from data_loader import load_qm7, make_batches\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We load the dataset, shuffle it and split it into a (larger) training set and a (smaller) testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape=(6500, 23, 23); X_test.shape=(665, 23, 23)\n",
      "y_train.shape=(6500,); y_test.shape=(665,)\n",
      "Energies: (-1537.1790771484375 +- 223.4197235107422) kcal/mol\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'atomization energy [kcal/mol]')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = load_qm7(n_train=6500)\n",
    "mean_y = np.mean(y_train)\n",
    "scale_y = np.std(y_train)\n",
    "print(f\"{X_train.shape=}; {X_test.shape=}\")\n",
    "print(f\"{y_train.shape=}; {y_test.shape=}\")\n",
    "print(f\"Energies: ({mean_y} +- {scale_y}) kcal/mol\")\n",
    "plt.figure()\n",
    "plt.hist(y_train, bins=20, label=\"Train\")\n",
    "plt.hist(y_test, bins=20, label=\"Test\")\n",
    "plt.legend()\n",
    "plt.title(\"Distribution of energies\")\n",
    "plt.xlabel(\"atomization energy [kcal/mol]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Our model will consist of two parts:\n",
    "1. **Calculating feature vectors** from the raw input\n",
    "2. **Applying a multi-layer-perceptron** to the obtained features\n",
    "\n",
    "For the feature vectors we follow the approach proposed by Rupp et al. in 2012: We compute the eigvalues of the Coulomb matrix $C$:\n",
    "\n",
    "$$C_{ii} = \\frac{1}{2}Z_i^{2.4} \\qquad C_{ij} = \\frac{Z_i Z_j}{|R_i - R_j|}$$\n",
    "\n",
    "\n",
    "The multi-layer perceptron consists of multiple rounds of a linear transformation and a non-linear function:\n",
    "$$x_{n+1} = \\sigma(x_n W_n + b_n)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_input_features(x):\n",
    "    return jnp.linalg.eigvalsh(x)\n",
    "\n",
    "def mlp(params, x):\n",
    "    for ind_layer, (weights, bias) in enumerate(params):\n",
    "        x = x @ weights + bias\n",
    "        if ind_layer != (len(params) - 1):\n",
    "            x = jax.nn.relu(x)\n",
    "    return x\n",
    "\n",
    "def model(params, x):\n",
    "    x = calculate_input_features(x)\n",
    "    y = mlp(params, x)\n",
    "    y = y * scale_y + mean_y\n",
    "    return y.flatten()\n",
    "\n",
    "def init_mlp(n_neurons, input_dim, output_dim):\n",
    "    dims_in = [input_dim] + n_neurons\n",
    "    dims_out = n_neurons + [output_dim]\n",
    "    params = []\n",
    "    for dim_in, dim_out in zip(dims_in, dims_out):\n",
    "        w_init = np.random.normal(loc=0, scale=2/(dim_in + dim_out), size=(dim_in, dim_out))\n",
    "        b_init = np.zeros(shape=(dim_out,))\n",
    "        params.append((w_init, b_init))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To optimize the model, we need to define a loss. For this task, we will use the standard mean square error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define a loss function and an optimizer / training-step\n",
    "def loss_func(params, x, y_target):\n",
    "    y_pred = model(params, x)\n",
    "    residual = (y_pred - y_target) / scale_y\n",
    "    return jnp.mean(residual**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To optimize the model we will use plain stochastic gradient descent with learning rate $\\eta$ to update our parameters $\\theta$:\n",
    "\n",
    "$$\\theta_{t+1} = \\theta_t - \\eta \\nabla_\\theta \\mathcal{L_t}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@jax.jit # equivalent to training_step = jax.jit(training_step)\n",
    "def training_step(params, batch, learning_rate):\n",
    "    x, y_target = batch\n",
    "    loss, grad = jax.value_and_grad(loss_func, argnums=0)(params, x, y_target)\n",
    "\n",
    "    # Because the grad and params are nested data structures we cannot directly work with them\n",
    "    # (e.g. new_params = params - learning_rate * grad), but need to\n",
    "    param_update = jax.tree_map(lambda g: -learning_rate * g, grad)\n",
    "    new_params = jax.tree_map(jnp.add, params, param_update)\n",
    "    return loss, new_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "During and after the training we will want to evaluate our models performance, by applying it to some data and computing the mean absolute error to the ground truth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def evaluate_model(params, X, y_target):\n",
    "    y_pred = model(params, X)\n",
    "    return y_pred, jnp.mean(jnp.abs(y_pred - y_target))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The training loop consists of two nested loops:\n",
    "- The outer loop runs over epochs. One epoch means having seen each sample in the training set once\n",
    "- The inner loop runs over batches within the epoch: We split the whole training set into smaller, randomly selected batches to obtain cheaper/faster gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0  , mae_train=173.2 kcal/mol, mae_test=175.9 kcal/mol\n",
      "epoch=5  , mae_train=128.2 kcal/mol, mae_test=132.4 kcal/mol\n",
      "epoch=10 , mae_train=162.9 kcal/mol, mae_test=165.3 kcal/mol\n",
      "epoch=15 , mae_train=110.0 kcal/mol, mae_test=114.2 kcal/mol\n",
      "epoch=20 , mae_train=121.8 kcal/mol, mae_test=125.8 kcal/mol\n",
      "epoch=25 , mae_train=146.9 kcal/mol, mae_test=149.9 kcal/mol\n",
      "epoch=30 , mae_train=105.8 kcal/mol, mae_test=110.3 kcal/mol\n",
      "epoch=35 , mae_train=101.0 kcal/mol, mae_test=106.0 kcal/mol\n",
      "epoch=40 , mae_train=104.0 kcal/mol, mae_test=109.4 kcal/mol\n",
      "epoch=45 , mae_train=104.0 kcal/mol, mae_test=108.5 kcal/mol\n",
      "Mean absolute error (MAE) on training set: 101.3 kcal/mol\n",
      "Mean absolute error (MAE) on test set   : 106.1 kcal/mol\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network and run the actual training\n",
    "n_neurons_per_layer = [50, 50, 20]\n",
    "learning_rate = 0.01\n",
    "n_batches = 100\n",
    "n_epochs = 50\n",
    "params = init_mlp(n_neurons_per_layer, input_dim=X_train.shape[-1], output_dim=1)\n",
    "params_averaged = params\n",
    "\n",
    "mae_test = np.zeros(n_epochs)\n",
    "mae_train = np.zeros(n_epochs)\n",
    "loss = np.zeros(n_epochs * n_batches)\n",
    "ind_step = 0\n",
    "for ind_epoch in range(n_epochs):\n",
    "    for batch in make_batches(X_train, y_train, n_batches):\n",
    "        loss[ind_step], params = training_step(params, batch, learning_rate)\n",
    "        ind_step += 1\n",
    "    y_pred_train, mae_train[ind_epoch] = evaluate_model(params, X_train, y_train)\n",
    "    y_pred_test, mae_test[ind_epoch] = evaluate_model(params, X_test, y_test)\n",
    "    if (ind_epoch % 5) == 0:\n",
    "        print(f\"epoch={ind_epoch:<3d}, mae_train={mae_train[ind_epoch]:.1f} kcal/mol, mae_test={mae_test[ind_epoch]:.1f} kcal/mol\")\n",
    "\n",
    "# Analyze final model\n",
    "print(f\"Mean absolute error (MAE) on training set: {mae_train[-1]:.1f} kcal/mol\")\n",
    "print(f\"Mean absolute error (MAE) on test set   : {mae_test[-1]:.1f} kcal/mol\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After training we can plot the learning curves, as well as a scatter plot of our final model's performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axes = plt.subplots(1,3, dpi=100, figsize=(10,8))\n",
    "axes[0].semilogy(loss)\n",
    "axes[0].set_title(\"Training loss\")\n",
    "\n",
    "axes[1].plot(mae_train, label=\"Train\")\n",
    "axes[1].plot(mae_test, label=\"Test\")\n",
    "axes[1].set_title(\"Mean absolute error [kcal/mol]\")\n",
    "axes[1].legend()\n",
    "\n",
    "axes[2].scatter(y_train, y_pred_train, label=\"Train\")\n",
    "axes[2].scatter(y_test, y_pred_test, label=\"Test\")\n",
    "axes[2].legend()\n",
    "axes[2].set_xlabel(\"Ground truth [kcal/mol]\")\n",
    "axes[2].set_ylabel(\"Predicted [kcal/mol]\")\n",
    "axes[2].plot([-2000, -500], [-2000, -500], color='gray', ls='--')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}